---
title: "Machine Learning Project"
---


**Your Name**: Devin M Rohler
**Your G Number**: 010



```{r warning = FALSE, message = FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)

library(tidyverse)
library(tidymodels)
library(viridis)
library(ggplot2)
library(parsnip)
library(discrim)
credit_card_df <- readRDS(url('https://gmubusinessanalytics.netlify.app/data/credit_card_df.rds'))

```



# Data Analysis

In this section, you must think of at least 5 relevant questions that explore the relationship between `customer_status` and the other variables in the `credit_card_df` data set. The goal of your analysis should be discovering which variables drive the differences between customers who do and do not close their account.

You must answer each question and provide supporting data summaries with either a summary data frame (using `dplyr`/`tidyr`) or a plot (using `ggplot`) or both.

In total, you must have a minimum of 3 plots (created with `ggplot`) and 3 summary data frames (created with `dplyr`) for the exploratory data analysis section. Among the plots you produce, you must have at least 3 different types (ex. box plot, bar chart, histogram, scatter plot, etc...)

See the [Data Analysis Project](https://gmubusinessanalytics.netlify.app/data-analysis-project.html){target="_blank"} for an example of a question answered with a summary table and plot.

**Note**: To add an R code chunk to any section of your project, you can use the keyboard shortcut `Ctrl` + `Alt` + `i` or the `insert` button at the top of your R project template notebook file.



# Question 1


**Question**: What affect does month_inactive_last_year have on customer_status ? 


**Answer**: It seems that those who closed their accounts had a higher amount of time inactive. This may be be due to customers not using their card relaizing that they do not need the account then close it.


```{r}
#summary 1
credit_card_df %>% group_by(customer_status) %>%
  summarise(n_customers = n(),
            average_value = mean(months_inactive_last_year),
            max_value = max(months_inactive_last_year),
            min_value = min(months_inactive_last_year)) %>%
  arrange(desc(average_value))
```



# Question 2


**Question**: Does the type of card a customer has have an affect on their status?


**Answer**: Card type does seems to change. It seems that those who closed thier accounts were more likely to have the blue card. There may be a certain charactersitic that blue card carries have. 


```{r}
#plot 1
ggplot(data = credit_card_df, aes(x = card_type, fill = customer_status)) + 
   geom_bar() + 
   scale_fill_manual(values = c('darkorange','blue')) +
   labs(title = "Figure 2. Customer Card Type in Relation to Status",
           x = "Card Type" , y = "Count", fill = "Customer Status")

```


# Question 3


**Question**: Does the amount spent and amount of transactions per year affect if a customer cancels thier service ?


**Answer**: It seems that the lower amount and transaction a customer has they are more likely to cancel their service. As total amount spent goes up, the amount of transactions goes down. Past the $10,000 mark it seems that really no one cancels thier service. There is a linear relation between these variables.


```{r}
#plot 2
ggplot(data = credit_card_df,aes(x= total_spend_last_year, y = transactions_last_year, color = customer_status)) +
  geom_point(fill = "#006EA1") +
  geom_smooth(color = 'red') +
  scale_color_manual(values = c('darkorchid2','chartreuse3')) +
  labs(title = "Figure 2.Relationship Between Amount Spent & # of Transations on Customer Status",
       x = 'Total Spend Last Year($)', y = 'Amount of Transaction Last Year',
       color = 'Total Claims') +
    theme_bw() +
     theme(plot.title = element_text(size = 10, color = "midnightblue"), 
         axis.title.x = element_text(size = 10, color = "midnightblue"),
         axis.title.y = element_text(size = 10, color = "midnightblue"))
```



# Question 4


**Question**: Does the amount of accounts a customer has have an affect on their status ?


**Answer**: it seems that on average customers that have more accounts with the company are more likely to keep thier services. Those who kept had an average of almost .8 more accounts. 


```{r}
#summary 2
credit_card_df %>% group_by(customer_status) %>%
  summarise(n_customers = n(),
            average_value = mean(total_accounts),
            max_value = max(contacted_last_year),
            min_value = min(contacted_last_year)) %>%
  arrange(desc(average_value))
```



# Question 5


**Question**: does a customers current credit limit have an affect on thier status


**Answer**: Credit limit seems to be higher in those who have an active account. The higher limit may keep customers around and spending.


```{r}
#summary 3
credit_card_df %>% group_by(customer_status) %>%
  summarise(n_customers = n(),
            average_value = mean(credit_limit),
            max_value = max(credit_limit),
            min_value = min(credit_limit)) %>%
  arrange(desc(average_value))

#figure 3
ggplot(data = credit_card_df,aes(x=customer_status, y = credit_limit)) +
  geom_boxplot(fill = "#006EA1") +
  labs(title = 'Figure 3. Credit Limit by Customer Status', x = 'Customer Status',
       y = 'Credit Limit($)') +
    theme_bw() +
     theme(plot.title = element_text(size = 10, color = "blue"), 
         axis.title.x = element_text(size = 10, color = "blue"),
         axis.title.y = element_text(size = 10, color = "blue"))
```







# Machine Learning


In this section of the project, you will fit **three classification algorithms** to predict the outcome variable,`customer_status`.

You must follow the machine learning steps below. 

The data splitting and feature engineering steps should only be done once so that your models are using the same data and feature engineering steps for training.

- Split the `credit_card_df` data into a training and test set (remember to set your seed)
- Specify a feature engineering pipeline with the `recipes` package
    - You can include steps such as skewness transformation, correlation filters, dummy variable encoding or any other steps you find appropriate
- Specify a `parsnip` model object
    - You may choose from the following classification algorithms:
      - Logistic Regression
      - LDA
      - QDA
      - KNN
      - Decision Tree
      - Random Forest
- Package your recipe and model into a workflow
- Fit your workflow to the training data
    - If your model has hyperparameters:
      - Split the training data into 5 folds for 5-fold cross validation using `vfold_cv` (remember to set your seed)
      - Perform hyperparamter tuning with a random grid search using the `grid_random()` function
      - Refer to the following tutorial for an example - [Random Grid Search](https://gmubusinessanalytics.netlify.app/lesson-08-r-tutorial.html#Hyperparameter_Tuning14){target="_blank"}
      - Hyperparameter tuning can take a significant amount of computing time. Be careful not to set the `size` argument of `grid_random()` too large. I recommend `size` = 10 or smaller.
      - Select the best model with `select_best()` and finalize your workflow
- Evaluate model performance on the test set by plotting an ROC curve using `autoplot()` and calculating the area under the ROC curve on your test data






#splitting and engineering
```{r}
#seed
set.seed(757)
#initial split
credit_split <- initial_split(credit_card_df, prop = 0.75,
                             strata = customer_status)
#view split
credit_split
#training & test
credit_training <- credit_split %>% training()
credit_test <- credit_split %>% testing()
#folds
credit_folds <- vfold_cv(credit_training, v =5)
```

```{r}
#recipe
credit_recipe <- recipe(customer_status ~., data = credit_training) %>%
  #transformations
  step_corr(all_numeric(),-all_outcomes()) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(),-all_outcomes()) %>% 
  #prep
  prep(training = credit_training)

#apply to test
  credit_recipe %>% bake(new_data = credit_test)
```



# Model 1

```{r}
#logisitc Regression
logistic_model <- logistic_reg() %>%
                  set_engine("glm") %>%
                  set_mode("classification")
#Workflow 
logistic_wf <- workflow() %>%
               add_model(logistic_model) %>%
               add_recipe(credit_recipe)
#fit model 
logistic_fit <- logistic_wf %>%
                fit(data = credit_training)

credit_trained_model <- logistic_fit %>%
  pull_workflow_fit()

#predictions
prediction_categories <- predict(logistic_fit,
                                 new_data = credit_test)

prediction_categories


prediction_probabilities <- predict(logistic_fit,
                                    new_data = credit_test,
                                    type = 'prob')
prediction_probabilities

#combine
test_results <- credit_test %>% select(customer_status) %>%
  bind_cols(prediction_categories) %>% bind_cols(prediction_probabilities)
test_results
```
```{r}
#results
#Confusion Matrix 
conf_mat(test_results,
         truth = customer_status,
         estimate = .pred_class)
#specificity 
spec(test_results,
     truth = customer_status,
     estimate = .pred_class)
#roc curve
roc_curve(test_results,
          truth = customer_status,
          estimate = .pred_closed_account) %>% 
  autoplot()
#roc auc
roc_auc(test_results,
        truth = customer_status,
        .pred_closed_account)
#f1 
f_meas(test_results,
       truth = customer_status,
       estimate = .pred_class)
```




# Model 2

```{r}
#LDA
lda_model <- discrim_regularized(frac_common_cov = 1) %>%
  set_engine('klaR') %>%
  set_mode('classification')
#Workflow
lda_wf <- workflow() %>%
  add_model(lda_model) %>%
  add_recipe(credit_recipe)
#fit
lda_fit <- lda_wf %>%
  last_fit(split = credit_split)
#collect predictions
lda_results <- lda_fit %>%
  collect_predictions()
```
```{r}
#results
#Roc Curve
roc_curve(lda_results,
          truth = customer_status,
          estimate = .pred_closed_account) %>%
autoplot()
#Roc AUC 
roc_auc(lda_results,
        truth = customer_status,
        estimate = .pred_closed_account)
#Confusion Matrix
conf_mat(lda_results,
         truth = customer_status,
         estimate = .pred_class)
#f
f_meas(lda_results,
       truth = customer_status,
       estimate = .pred_class)
```




# Model 3

```{r}
#QDA
qda_model <- discrim_regularized(frac_common_cov = 0) %>%
  set_engine('klaR') %>%
  set_mode('classification')
#Workflow
qda_wf <- workflow() %>%
  add_model(qda_model) %>%
  add_recipe(credit_recipe)
#fit
qda_fit <- qda_wf %>%
  last_fit(split = credit_split)
#collect predictions
qda_results <- qda_fit %>%
  collect_predictions()
```
```{r}
#results
#Roc Curve
roc_curve(qda_results,
          truth = customer_status,
          estimate = .pred_closed_account) %>%
autoplot()
#Roc AUC 
roc_auc(qda_results,
        truth = customer_status,
        estimate = .pred_closed_account)
#Confusion Matrix
conf_mat(qda_results,
         truth = customer_status,
         estimate = .pred_class)
#f
f_meas(qda_results,
       truth = customer_status,
       estimate = .pred_class)
```



# Summary of Results

Write a summary of your overall findings and recommendations to the executives at the bank. Think of this section as your closing remarks of a presentation, where you summarize your key findings, model performance, and make recommendations to improve customer retention and service at the bank.

Your executive summary must be written in a [professional tone](https://www.universalclass.com/articles/writing/business-writing/appropriate-tone-in-business-communications.htm){target="_blank"}, with minimal grammatical errors, and should include the following sections:

1. An introduction where you explain the business problem and goals of your data analysis

    - What problem(s) is this company trying to solve? Why are they important to their future success?
  
    - What was the goal of your analysis? What questions were you trying to answer and why do they matter?

<br>

2. Highlights and key findings from your Exploratory Data Analysis section 
    - What were the interesting findings from your analysis and **why are they important for the business**?

    - This section is meant to **establish the need for your recommendations** in the following section

<br>

3. Your “best” classification model and an analysis of its performance 
    - In this section you should talk about the expected error of your model on future data
      - To estimate future performance, you can use your model performance results on the **test data**
    - You should discuss at least one performance metric, such as an F1, sensitivity, specificity, or ROC AUC for your model. However, you must explain the results in an **intuitive, non-technical manner**. Your audience in this case are executives at a bank with limited knowledge of machine learning.

<br>

4. Your recommendations to the bank on how to reduce the number of customers closing their credit card accounts 
  
    - Each recommendation must be supported by your data analysis results 

    - You must clearly explain why you are making each recommendation and which results from your data analysis support this recommendation

    - You must also describe the potential business impact of your recommendation:
      
      - Why is this a good recommendation? 
      
      - What benefits will the business achieve?


**Summary**

Add your summary here. Please do not place your text within R code chunks.

	In recent times it seems that your company has been experiencing issues with customer cancellation. As with many businesses profit is a main motive. If customers are constantly leaving, this will affect your total profits. You would like to be able to figure out what attributes a person carries that may lead them to cancelling service. You may also be able to use these variables to decide if you want to start a card with them in the first place. With our in-depth data analysis and modeling process we aim to be able to give you advice on what variables and at what levels may lead your customers to cancel their service. The goal is to give as much insight as possible to be able to help you keep more customer and in turn increase overall profits.  
	
	In this section we will discuss some key insights from the data analysis process. The first variable that was explored was the length of inactivity in the previous year.  Here we saw that those who cancelled their service had .4 months more of inactivity on average then those who did not.  This is important to look at, it seems that the more time a person does not use their account the more likely they are to cancel their account. This may be due to them realizing they do not need the account after not using it for such a long time. The second variable that was looked at was the type of card that a customer had. It seems that those who had the “blue” card had the most cancellations around 2600 cancellations and those with “silver” and “gold” had 1200 and 900 respectively.  Blue card has only 1100 current active accounts. This may be due to customers not getting enough credit or rewards at the blue level.  The next variables that were looked at were looked at was the amount of money spent and amount transactions per year. It seemed that the lower number of transactions and amount spent the more likely the customer was going to cancel their service. There seems to be a clear linear relationship between these variables as total transactions and cost went up, number of cancelations went down. This could be  again the less a customer uses a card the more likely they are to cancel It. Past around $10,000 spent no customers cancelled their service. The next variable was the amount of account a customer had. On average those who had more accounts were less likely to cancel their accounts. Those who did not cancel had .7 more accounts on average. This may be due to if a customer has more accounts, they may like the company more or like the services they provide better. The last variable that was looked at was the amount of credit a customer had. On average those who did not cancel their account had $649 more of available credit. A lower credit amount may have made customer cancel their accounts. This in-depth data analysis brought many good insights into what drives a customer to cancel their service.
	
	The next process that was carried out was the modeling process. Multiple models and model types were ran to be able to decide which variables, attributes and values had the biggest effect on customer cancelation.  Based on these the models were able to predict whether a customer would cancel their service based on the available dataset. The model that performed the best was the Quadratic Discriminant Analysis. We won’t go into exactly what the means, but the model was used to predict whether a customer would cancel their service or not.  The model had an F1 score of .831244, that means that it predicted just over 83% of the customers correct.  The model predicted 982 out of 1157 customers with the correct attribute. This is model performed pretty good in a general sense. 
	
	This section will use the data analysis to make some informed suggestions to improve customer retention and give the company the ability to predict customer status. The first suggestion is to increase the rewards or credit limit on the blue card. More customers cancelled their account then kept it who had the blue card around 2600 cancellations. There is obviously some problem or lack of something with this card, other card types did not have nearly the proportion of cancellations. An increase credit line or rewards program would make the customers feel appreciated and spend more money working towards rewards. This would then increase profits which would benefit the business. This carries into the next recommendation. Customers who spent more money and had more transactions were less likely to cancel their accounts. If the company can create a tier or reward system where customers work towards by spending money it will increase profits and retention. The next recommendation is trying to get customers to open more accounts. Giving users discounts for cards for spouses and kids will make users want to open more accounts and in tern spend more money. The more accounts that are open mean the more money that is being spent which mean profits for the business. 


